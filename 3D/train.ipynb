{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x23e7c6a2090>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import monai\n",
    "import torch\n",
    "import shutil\n",
    "import argparse\n",
    "import warnings\n",
    "import datetime\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import nibabel as nib\n",
    "from pathlib import Path\n",
    "from unet_3d import Unet_3d\n",
    "import monai.transforms as mt\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics import IoU, F1\n",
    "from attn_unet_3d import Attn_UNet3d\n",
    "from matplotlib import pyplot as plt\n",
    "from pytorch_lightning import Trainer\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import KFold\n",
    "from torchmetrics.functional import dice_score, iou\n",
    "from data_3d import train_loader_ACDC, val_loader_ACDC\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
    "from pytorch_lightning.loggers import TensorBoardLogger, CSVLogger\n",
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator as ea\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", \".*Consider increasing the value of the `num_workers` argument*\")\n",
    "torch.manual_seed(12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Arguments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters directly\n",
    "model_choice = 'Unet_3d'\n",
    "kfolds = 5\n",
    "batch_size_train = 2\n",
    "batch_size_val = 2\n",
    "lr = 0.001\n",
    "lr_decay = 0.9\n",
    "gpus = 1\n",
    "maximum_epochs = 10\n",
    "patience_early_stop = 5\n",
    "monitor = 'val_loss'\n",
    "monitor_mode = 'min'\n",
    "optimizer_choice = 'adam'\n",
    "scheduler_choice = 'StepLR'\n",
    "dropout_rate = 0.5\n",
    "scheduler_patience = 5\n",
    "\n",
    "# Use these variables in your training code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: Unet_3d\n",
      "Model Summary: Unet_3d(\n",
      "  (max_pool3d): MaxPool3d(kernel_size=(2, 2, 1), stride=(2, 2, 1), padding=0, dilation=1, ceil_mode=True)\n",
      "  (drop): Dropout3d(p=0.5, inplace=False)\n",
      "  (upsample3d): Upsample(scale_factor=(2.0, 2.0, 1.0), mode='trilinear')\n",
      "  (down_conv1): Sequential(\n",
      "    (0): Conv3d(1, 26, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same)\n",
      "    (1): BatchNorm3d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "    (3): Conv3d(26, 26, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same)\n",
      "    (4): BatchNorm3d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "  )\n",
      "  (down_conv2): Sequential(\n",
      "    (0): Conv3d(26, 52, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same)\n",
      "    (1): BatchNorm3d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "    (3): Conv3d(52, 52, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same)\n",
      "    (4): BatchNorm3d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "  )\n",
      "  (down_conv3): Sequential(\n",
      "    (0): Conv3d(52, 104, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same)\n",
      "    (1): BatchNorm3d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "    (3): Conv3d(104, 104, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same)\n",
      "    (4): BatchNorm3d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "  )\n",
      "  (down_conv4): Sequential(\n",
      "    (0): Conv3d(104, 208, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same)\n",
      "    (1): BatchNorm3d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "    (3): Conv3d(208, 208, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same)\n",
      "    (4): BatchNorm3d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "  )\n",
      "  (down_conv5): Sequential(\n",
      "    (0): Conv3d(208, 416, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same)\n",
      "    (1): BatchNorm3d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "    (3): Conv3d(416, 416, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same)\n",
      "    (4): BatchNorm3d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "  )\n",
      "  (up_conv1): Sequential(\n",
      "    (0): Conv3d(624, 208, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same)\n",
      "    (1): BatchNorm3d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "    (3): Conv3d(208, 208, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same)\n",
      "    (4): BatchNorm3d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "  )\n",
      "  (up_conv2): Sequential(\n",
      "    (0): Conv3d(312, 104, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same)\n",
      "    (1): BatchNorm3d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "    (3): Conv3d(104, 104, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same)\n",
      "    (4): BatchNorm3d(104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "  )\n",
      "  (up_conv3): Sequential(\n",
      "    (0): Conv3d(156, 52, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same)\n",
      "    (1): BatchNorm3d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "    (3): Conv3d(52, 52, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same)\n",
      "    (4): BatchNorm3d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "  )\n",
      "  (up_conv4): Sequential(\n",
      "    (0): Conv3d(78, 26, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same)\n",
      "    (1): BatchNorm3d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "    (3): Conv3d(26, 26, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same)\n",
      "    (4): BatchNorm3d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "  )\n",
      "  (final): Conv3d(26, 4, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "  (deep1): Conv3d(104, 4, kernel_size=(1, 1, 1), stride=(1, 1, 1), padding=same)\n",
      "  (deep2): Conv3d(52, 4, kernel_size=(1, 1, 1), stride=(1, 1, 1), padding=same)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Function to parse arguments (with default values for Jupyter)\n",
    "def parse_arguments():\n",
    "    if 'ipykernel' in sys.modules or get_ipython():\n",
    "        return argparse.Namespace(\n",
    "            model_choice='Unet_3d',\n",
    "            kfolds=5,\n",
    "            Batch_size_train=2,\n",
    "            Batch_size_val=2,\n",
    "            lr=0.001,\n",
    "            lr_decay=0.9,\n",
    "            gpus=1,\n",
    "            maximum_epochs=10,\n",
    "            patience_early_stop=5,\n",
    "            monitor='val_loss',\n",
    "            Monitor_mode='min',\n",
    "            optimizer_choice='adam',\n",
    "            scheduler_choice='StepLR',\n",
    "            dropout_rate=0.5,\n",
    "            scheduler_patience=5\n",
    "        )\n",
    "    else:\n",
    "        parser = argparse.ArgumentParser()\n",
    "        parser.add_argument('--model_choice', default='Unet_3d', choices=['Unet_3d', 'Attn_UNet3d'], help='Model choice')\n",
    "        parser.add_argument('--kfolds', default=5, type=int, help='Number of K-Folds')\n",
    "        parser.add_argument('--Batch_size_train', default=2, type=int, help='Training batch size')\n",
    "        parser.add_argument('--Batch_size_val', default=2, type=int, help='Validation batch size')\n",
    "        parser.add_argument('--lr', default=0.001, type=float, help='Learning rate')\n",
    "        parser.add_argument('--lr_decay', default=0.9, type=float, help='Learning rate decay')\n",
    "        parser.add_argument('--gpus', default=1, type=int, help='Number of GPUs to use')\n",
    "        parser.add_argument('--maximum_epochs', default=10, type=int, help='Maximum number of training epochs')\n",
    "        parser.add_argument('--patience_early_stop', default=5, type=int, help='Patience for early stopping')\n",
    "        parser.add_argument('--monitor', default='val_loss', help='Metric to monitor for early stopping')\n",
    "        parser.add_argument('--Monitor_mode', default='min', help='Mode for monitoring metric')\n",
    "        parser.add_argument('--optimizer_choice', default='adam', choices=['adam', 'SGD'], help='Optimizer choice')\n",
    "        parser.add_argument('--scheduler_choice', default='StepLR', help='Scheduler choice')\n",
    "        parser.add_argument('--dropout_rate', default=0.5, type=float, help='Dropout rate')\n",
    "        parser.add_argument('--scheduler_patience', default=5, type=int, help='Patience for learning rate scheduler')\n",
    "\n",
    "        return parser.parse_args()\n",
    "\n",
    "# Parse the arguments\n",
    "args = parse_arguments()\n",
    "\n",
    "# Select the model based on the parsed arguments\n",
    "if args.model_choice == \"Unet_3d\":\n",
    "    my_model = Unet_3d(drop=args.dropout_rate).cuda()  # without attention\n",
    "elif args.model_choice == \"Attn_UNet3d\":\n",
    "    my_model = Attn_UNet3d(drop=args.dropout_rate).cuda()  # with attention\n",
    "else:\n",
    "    raise ValueError(\"Wrong model choice!\")\n",
    "\n",
    "# IoU and F1 Metrics\n",
    "IOU_metric = IoU(num_classes=4, absent_score=-1., reduction='none').cuda()\n",
    "f1_metric = F1(num_classes=4, mdmc_average='samplewise', average='none').cuda()\n",
    "\n",
    "# Softmax\n",
    "soft = torch.nn.Softmax(dim=1)\n",
    "\n",
    "# Target and crop shapes\n",
    "tar_shape = [300, 300, 18]\n",
    "crop_shape = [224, 224, 10]\n",
    "\n",
    "# Example to check\n",
    "print(f\"Using model: {args.model_choice}\")\n",
    "print(f\"Model Summary: {my_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"---------Augmentations---------\"\"\"\n",
    "train_compose = mt.Compose(\n",
    "    [\n",
    "        mt.ResizeWithPadOrCropD(keys=[\"image\", \"mask\"], spatial_size=tar_shape),\n",
    "        mt.RandSpatialCropD(keys=[\"image\", \"mask\"], roi_size=crop_shape, random_center=True, random_size=False),\n",
    "        mt.RandRotate90D(keys=[\"image\", \"mask\"], prob=0.5, spatial_axes=(0, 1)),\n",
    "        mt.RandAxisFlipD(keys=[\"image\", \"mask\"], prob=0.5),\n",
    "        mt.RandKSpaceSpikeNoiseD(keys=[\"image\"], intensity_range=(5.0, 7.5), prob=0.15),\n",
    "        mt.RandGaussianNoiseD(keys=[\"image\"], mean=0.0, std=0.2, prob=0.25),\n",
    "        # mt.RandAffineD(keys=[\"image\", \"mask\"], prob=0.15, rotate_range=(0, 0, 2), translate_range=(0, 0, 2),\n",
    "        #                scale_range=(0, 0, 2), mode=\"nearest\"),\n",
    "        mt.ToTensorD(keys=[\"image\", \"mask\"], allow_missing_keys=False)\n",
    "\n",
    "    ]\n",
    ")\n",
    "val_compose = mt.Compose(\n",
    "    [\n",
    "        mt.ToTensorD(keys=[\"image\", \"mask\"], allow_missing_keys=False),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"------------------Datasets and Directories to save the results------------------\"\"\"\n",
    "# Define the K-fold Cross Validator\n",
    "splits = KFold(n_splits=kfolds, shuffle=True, random_state=12345)\n",
    "\n",
    "# train + val dataset for 5 fold cross validation training\n",
    "concatenated_dataset = train_loader_ACDC(transform=None, train_index=None)\n",
    "\n",
    "if not os.path.exists(\"unet\"):\n",
    "    os.mkdir(\"unet\")\n",
    "\n",
    "#  path to store the checkpoints and the best model\n",
    "if not os.path.exists(\"unet/checkpoints\"):\n",
    "    os.mkdir(\"unet/checkpoints\")\n",
    "checkpoint_path = \"unet/checkpoints\"\n",
    "\n",
    "if not os.path.exists(\"unet/tb_logs\"):\n",
    "    os.mkdir(\"unet/tb_logs\")\n",
    "tb_path = \"unet/tb_logs\"\n",
    "\n",
    "if not os.path.exists(\"unet/csv_logs\"):\n",
    "    os.mkdir(\"unet/csv_logs\")\n",
    "csv_path = \"unet/csv_logs\"\n",
    "\n",
    "# Temporarily store the validated image and ground truth plots --> to be moved to the respective folders\n",
    "if not os.path.exists(r'unet/val_images_temp_3d/'):\n",
    "    os.makedirs(r'unet/val_images_temp_3d/')\n",
    "val_path = r'unet/val_images_temp_3d/'\n",
    "\n",
    "# Save the validation images and ground truths\n",
    "if not os.path.exists(r'unet/val_images_save_3d/'):\n",
    "    os.makedirs(r'unet/val_images_save_3d/')\n",
    "image_path = r'unet/val_images_save_3d/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"---------Post Processing---------\"\"\"\n",
    "keep_largest = monai.transforms.KeepLargestConnectedComponent(applied_labels=[1, 2, 3])\n",
    "\n",
    "\n",
    "#  padding: just pass the image\n",
    "def Pad_images(image):\n",
    "    orig_shape = list(image.size())\n",
    "    original_x = orig_shape[2]\n",
    "    original_y = orig_shape[3]\n",
    "    original_z = orig_shape[4]\n",
    "    new_x = (16 - (original_x % 16)) + original_x\n",
    "    new_y = (16 - (original_y % 16)) + original_y\n",
    "    new_z = original_z\n",
    "    new_shape = [new_x, new_y, new_z]\n",
    "    b, c, h, w, d = image.shape\n",
    "    m = image.min()\n",
    "    x_max = new_shape[0]\n",
    "    y_max = new_shape[1]\n",
    "    z_max = new_shape[2]\n",
    "    result = torch.Tensor(b, c, x_max, y_max, z_max).fill_(m)\n",
    "    xx = (x_max - h) // 2\n",
    "    yy = (y_max - w) // 2\n",
    "    zz = (z_max - d) // 2\n",
    "    result[:, :, xx:xx + h, yy:yy + w, zz:zz + d] = image\n",
    "    return result, tuple([xx, yy, zz])  # result is a torch tensor in CPU --> have to move to GPU\n",
    "\n",
    "\n",
    "#  pass the padded image, the indices and the original shape\n",
    "def UnPad_imges(image, indices, org_shape):\n",
    "    b, c, h, w, d = org_shape\n",
    "    xx = indices[0]\n",
    "    yy = indices[1]\n",
    "    zz = indices[2]\n",
    "    return image[:, :, xx:xx + h, yy:yy + w, zz:zz + d]  # image is a torch tensor --> have to move to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"-----------------------------------------------------------------------------------\"\"\"\n",
    "# save the images\n",
    "def save_plots_image(img, idx, img_aff, img_aff_org):\n",
    "    out_path = os.path.join(val_path, f\"{idx}_image\" + '.nii.gz')\n",
    "    final_image = np.array(img.cpu())\n",
    "    final_image = np.squeeze(final_image)\n",
    "    img_aff = img_aff.squeeze().cpu()\n",
    "    affine = np.diag([torch.diagonal(img_aff)[0], torch.diagonal(img_aff)[1],\n",
    "                      torch.diagonal(img_aff)[2], torch.diagonal(img_aff)[3]])\n",
    "    final_image = nib.Nifti2Image(final_image, affine=affine)\n",
    "    nib.save(final_image, out_path)\n",
    "\n",
    "\n",
    "# save the masks\n",
    "def save_plots_mask(target, idx, gt_aff, gt_aff_org):\n",
    "    out_path = os.path.join(val_path, f\"{idx}_mask\" + '.nii.gz')\n",
    "    final_mask = np.array(target.cpu())\n",
    "    final_mask = np.squeeze(final_mask)\n",
    "    gt_aff = gt_aff.squeeze().cpu()\n",
    "    affine = np.diag([torch.diagonal(gt_aff)[0], torch.diagonal(gt_aff)[1],\n",
    "                      torch.diagonal(gt_aff)[2], torch.diagonal(gt_aff)[3]])\n",
    "    final_mask = nib.Nifti2Image(final_mask, affine=affine)\n",
    "    nib.save(final_mask, out_path)\n",
    "\n",
    "\n",
    "# save the predictions\n",
    "def save_plots_pred(pred, idx, pred_aff, pred_aff_org):\n",
    "    out_path = os.path.join(val_path, f\"{idx}_pred\" + '.nii.gz')\n",
    "    soft_pred_log = soft(pred)\n",
    "    final_pred_log = torch.argmax(soft_pred_log, dim=1)\n",
    "    # Post Processing after softmax and argmax\n",
    "    final_pred_log = keep_largest(final_pred_log)\n",
    "    ####################################################\n",
    "    final_pred_log = np.array(final_pred_log.cpu())\n",
    "    final_pred_log = np.squeeze(final_pred_log)\n",
    "    pred_aff = pred_aff.squeeze().cpu()\n",
    "    affine = np.diag([torch.diagonal(pred_aff)[0], torch.diagonal(pred_aff)[1],\n",
    "                      torch.diagonal(pred_aff)[2], torch.diagonal(pred_aff)[3]])\n",
    "    final_pred_log = nib.Nifti2Image(final_pred_log, affine=affine)\n",
    "    nib.save(final_pred_log, out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------- Fold 1 --------------------------\n",
      "Train Batch Size: 2 Val Batch Size: 2 Learning Rate: 0.001 Max epochs: 10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Wrong optimizer!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 291\u001b[0m\n\u001b[0;32m    287\u001b[0m         model\u001b[38;5;241m.\u001b[39mapply(reset_weights)\n\u001b[0;32m    290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 291\u001b[0m     \u001b[43mrun_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[36], line 209\u001b[0m, in \u001b[0;36mrun_training\u001b[1;34m()\u001b[0m\n\u001b[0;32m    205\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(max_epochs\u001b[38;5;241m=\u001b[39mmaximum_epochs, callbacks\u001b[38;5;241m=\u001b[39m[early_stop_callback, checkpoint_callback],\n\u001b[0;32m    206\u001b[0m                   gpus\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, logger\u001b[38;5;241m=\u001b[39m[tensorboard_logger, csv_logger],\n\u001b[0;32m    207\u001b[0m                   fast_dev_run\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, log_every_n_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    208\u001b[0m \u001b[38;5;66;03m# Training the model\u001b[39;00m\n\u001b[1;32m--> 209\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;66;03m# Save the best model\u001b[39;00m\n\u001b[0;32m    211\u001b[0m file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(model_choice) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_Best_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(dropout_rate) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_Fold_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(fold \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\nuzul\\.conda\\envs\\TugasAkhir\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:737\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, train_dataloader, ckpt_path)\u001b[0m\n\u001b[0;32m    732\u001b[0m     rank_zero_deprecation(\n\u001b[0;32m    733\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`trainer.fit(train_dataloader)` is deprecated in v1.4 and will be removed in v1.6.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    734\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Use `trainer.fit(train_dataloaders)` instead. HINT: added \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    735\u001b[0m     )\n\u001b[0;32m    736\u001b[0m     train_dataloaders \u001b[38;5;241m=\u001b[39m train_dataloader\n\u001b[1;32m--> 737\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    738\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[0;32m    739\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nuzul\\.conda\\envs\\TugasAkhir\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:682\u001b[0m, in \u001b[0;36mTrainer._call_and_handle_interrupt\u001b[1;34m(self, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;124;03mError handling, intended to be used only for main trainer function entry points (fit, validate, test, predict)\u001b[39;00m\n\u001b[0;32m    674\u001b[0m \u001b[38;5;124;03mas all errors should funnel through them\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    679\u001b[0m \u001b[38;5;124;03m    **kwargs: keyword arguments to be passed to `trainer_fn`\u001b[39;00m\n\u001b[0;32m    680\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 682\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    683\u001b[0m \u001b[38;5;66;03m# TODO: treat KeyboardInterrupt as BaseException (delete the code below) in v1.7\u001b[39;00m\n\u001b[0;32m    684\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n",
      "File \u001b[1;32mc:\\Users\\nuzul\\.conda\\envs\\TugasAkhir\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:772\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    770\u001b[0m \u001b[38;5;66;03m# TODO: ckpt_path only in v1.7\u001b[39;00m\n\u001b[0;32m    771\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m ckpt_path \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresume_from_checkpoint\n\u001b[1;32m--> 772\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    774\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[0;32m    775\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nuzul\\.conda\\envs\\TugasAkhir\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1141\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restore_modules_and_callbacks(ckpt_path)\n\u001b[0;32m   1140\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_configure_sharded_model()  \u001b[38;5;66;03m# allow user to setup in model sharded environment\u001b[39;00m\n\u001b[1;32m-> 1141\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1143\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m   1144\u001b[0m \u001b[38;5;66;03m# INSPECT THE CORE LOOPS\u001b[39;00m\n\u001b[0;32m   1145\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;124mfr\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;124m     Lightning internal flow looks like this:\u001b[39m\n\u001b[0;32m   1148\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTrainer\u001b[38;5;241m.\u001b[39mfit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTrainer\u001b[38;5;241m.\u001b[39mtest\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTrainer\u001b[38;5;241m.\u001b[39mpredict\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m  ||\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1168\u001b[0m \u001b[38;5;124m`pytorch_lightning/plugins/training_type_plugin` to find accelerator dispatch functions.\u001b[39m\n\u001b[0;32m   1169\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\nuzul\\.conda\\envs\\TugasAkhir\\Lib\\site-packages\\pytorch_lightning\\accelerators\\gpu.py:46\u001b[0m, in \u001b[0;36mGPUAccelerator.setup\u001b[1;34m(self, trainer)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msetup\u001b[39m(\u001b[38;5;28mself\u001b[39m, trainer: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpl.Trainer\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_nvidia_flags(trainer\u001b[38;5;241m.\u001b[39mlocal_rank)\n\u001b[1;32m---> 46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nuzul\\.conda\\envs\\TugasAkhir\\Lib\\site-packages\\pytorch_lightning\\accelerators\\accelerator.py:93\u001b[0m, in \u001b[0;36mAccelerator.setup\u001b[1;34m(self, trainer)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msetup_training_type_plugin()\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_type_plugin\u001b[38;5;241m.\u001b[39msetup_optimizers_in_pre_dispatch:\n\u001b[1;32m---> 93\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup_optimizers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msetup_precision_plugin()\n",
      "File \u001b[1;32mc:\\Users\\nuzul\\.conda\\envs\\TugasAkhir\\Lib\\site-packages\\pytorch_lightning\\accelerators\\accelerator.py:351\u001b[0m, in \u001b[0;36mAccelerator.setup_optimizers\u001b[1;34m(self, trainer)\u001b[0m\n\u001b[0;32m    349\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (TrainerFn\u001b[38;5;241m.\u001b[39mFITTING, TrainerFn\u001b[38;5;241m.\u001b[39mTUNING):\n\u001b[0;32m    350\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 351\u001b[0m optimizers, lr_schedulers, optimizer_frequencies \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_type_plugin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_optimizers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizers \u001b[38;5;241m=\u001b[39m optimizers\n\u001b[0;32m    355\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_schedulers \u001b[38;5;241m=\u001b[39m lr_schedulers\n",
      "File \u001b[1;32mc:\\Users\\nuzul\\.conda\\envs\\TugasAkhir\\Lib\\site-packages\\pytorch_lightning\\plugins\\training_type\\training_type_plugin.py:245\u001b[0m, in \u001b[0;36mTrainingTypePlugin.init_optimizers\u001b[1;34m(self, trainer, model)\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minit_optimizers\u001b[39m(\u001b[38;5;28mself\u001b[39m, trainer: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpl.Trainer\u001b[39m\u001b[38;5;124m\"\u001b[39m, model: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpl.LightningModule\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 245\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_optimizers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nuzul\\.conda\\envs\\TugasAkhir\\Lib\\site-packages\\pytorch_lightning\\trainer\\optimizers.py:35\u001b[0m, in \u001b[0;36mTrainerOptimizersMixin.init_optimizers\u001b[1;34m(self, model)\u001b[0m\n\u001b[0;32m     33\u001b[0m pl_module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mor\u001b[39;00m model\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lightning_optimizers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m optim_conf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfigure_optimizers\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpl_module\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpl_module\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optim_conf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     37\u001b[0m     rank_zero_warn(\n\u001b[0;32m     38\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     39\u001b[0m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[0;32m     40\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\nuzul\\.conda\\envs\\TugasAkhir\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1496\u001b[0m, in \u001b[0;36mTrainer.call_hook\u001b[1;34m(self, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1494\u001b[0m model_fx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(pl_module, hook_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   1495\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(model_fx):\n\u001b[1;32m-> 1496\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_fx\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;66;03m# *Bad code alert*\u001b[39;00m\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;66;03m# The `Accelerator` mostly calls the `TrainingTypePlugin` but some of those calls are deprecated.\u001b[39;00m\n\u001b[0;32m   1500\u001b[0m \u001b[38;5;66;03m# The following logic selectively chooses which hooks are called on each object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1504\u001b[0m \n\u001b[0;32m   1505\u001b[0m \u001b[38;5;66;03m# call the accelerator hook\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hook_name \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_train_start\u001b[39m\u001b[38;5;124m\"\u001b[39m,) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator, hook_name):\n",
      "Cell \u001b[1;32mIn[36], line 143\u001b[0m, in \u001b[0;36mTrain_3D.configure_optimizers\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    141\u001b[0m     optim \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlearning_rate, eps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-8\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m, amsgrad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWrong optimizer!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m scheduler_choice \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplateau\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    145\u001b[0m     scheduler \u001b[38;5;241m=\u001b[39m ReduceLROnPlateau(optim, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m, factor\u001b[38;5;241m=\u001b[39mLR_decay_rate, patience\u001b[38;5;241m=\u001b[39mscheduler_patience)\n",
      "\u001b[1;31mValueError\u001b[0m: Wrong optimizer!"
     ]
    }
   ],
   "source": [
    "\"\"\"-----------------------------------------------------------------------------------\"\"\"\n",
    "class Train_3D(pl.LightningModule):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Train_3D, self).__init__()\n",
    "        self.net = model_choice\n",
    "        self.loss_function = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        img, mask = batch[\"image\"], batch[\"mask\"]  # image --> torch.float(), mask --> torch.Long\n",
    "        img = img.float()\n",
    "        mask = mask.long()\n",
    "        mask = mask.squeeze(dim=1)\n",
    "        # image passed through the model\n",
    "        out = self(img)\n",
    "        # loss\n",
    "        loss = self.loss_function(out, mask)\n",
    "        soft_out = soft(out)\n",
    "        \"\"\" Calculation of metrics using Torchmetrics\"\"\"\n",
    "        # # iou\n",
    "        # iou_all = IOU_metric(soft_out, mask)\n",
    "        # iou_all = iou_all[iou_all != -1.]\n",
    "        # if len(iou_all) == 0:\n",
    "        #     train_iou = 0.0\n",
    "        # else:\n",
    "        #     train_iou = iou_all.mean()\n",
    "        # # dice score\n",
    "        # dice_all = f1_metric(soft_out, mask)\n",
    "        # dice_all = dice_all[dice_all != torch.isnan(dice_all)]\n",
    "        # if len(dice_all) == 0:\n",
    "        #     train_dice = 0.0\n",
    "        # else:\n",
    "        #     train_dice = dice_all.mean()\n",
    "        \"\"\" Calculation of metrics using Torchmetrics functional\"\"\"\n",
    "        # iou\n",
    "        iou_all = iou(soft_out, mask, absent_score=-1., num_classes=4, reduction='none', ignore_index=None)\n",
    "        iou_all = iou_all[iou_all != -1.]\n",
    "        if len(iou_all) == 0:\n",
    "            train_iou = torch.tensor(0.0).cuda()\n",
    "        else:\n",
    "            train_iou = iou_all.mean()\n",
    "        # dice score\n",
    "        dice_all = dice_score(soft_out, mask, bg=True, no_fg_score=-1., reduction='none')\n",
    "        dice_all = dice_all[dice_all != -1.]\n",
    "        if len(dice_all) == 0:\n",
    "            train_dice = torch.tensor(0.0).cuda()\n",
    "        else:\n",
    "            train_dice = dice_all.mean()\n",
    "        # logger\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=False, prog_bar=True)\n",
    "        return {\"loss\": loss, \"train_iou\": train_iou, \"train_dice\": train_dice}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        img, mask = batch[\"image\"], batch[\"mask\"]  # image --> torch.float(), mask --> torch.Long\n",
    "        img = img.float()\n",
    "        mask = mask.long()\n",
    "        ###############################################\n",
    "        img_affine = batch['image_meta_dict']['affine']\n",
    "        mask_affine = batch['mask_meta_dict']['affine']\n",
    "        image_affine_original = batch['image_meta_dict']['original_affine']\n",
    "        mask_affine_original = batch['mask_meta_dict']['original_affine']\n",
    "        ###############################################\n",
    "        save_plots_image(img, batch_idx, img_affine, image_affine_original)  # save the images\n",
    "        save_plots_mask(mask, batch_idx, mask_affine, mask_affine_original)  # save the masks\n",
    "        ###############################################\n",
    "        mask = mask.squeeze(dim=1)\n",
    "        # pad the image\n",
    "        padded_image, ind = Pad_images(img)\n",
    "        padded_image = padded_image.cuda()\n",
    "        # image passed through the model\n",
    "        out = self(padded_image).cuda()\n",
    "        # unpad the image\n",
    "        unpadded_prediction = UnPad_imges(out, ind, img.shape)\n",
    "        unpadded_prediction = unpadded_prediction.cuda()\n",
    "        ###############################################\n",
    "        save_plots_pred(unpadded_prediction, batch_idx, img_affine, image_affine_original)  # save the predictions\n",
    "        ###############################################\n",
    "        # loss\n",
    "        loss = self.loss_function(unpadded_prediction, mask)\n",
    "        # softmax\n",
    "        soft_out = soft(unpadded_prediction)\n",
    "        \"\"\" Calculation of metrics using Torchmetrics\"\"\"\n",
    "        # # iou\n",
    "        # iou_all = IOU_metric(soft_out, mask)\n",
    "        # iou_all = iou_all[iou_all != -1.]\n",
    "        # if len(iou_all) == 0:\n",
    "        #     val_iou = 0.0\n",
    "        # else:\n",
    "        #     val_iou = iou_all.mean()\n",
    "        # # dice score\n",
    "        # dice_all = f1_metric(soft_out, mask)\n",
    "        # dice_all = dice_all[dice_all != torch.isnan(dice_all)]\n",
    "        # if len(dice_all) == 0:\n",
    "        #     val_dice = 0.0\n",
    "        # else:\n",
    "        #     val_dice = dice_all.mean()\n",
    "        \"\"\" Calculation of metrics using Torchmetrics functional\"\"\"\n",
    "        # iou\n",
    "        iou_all = iou(soft_out, mask, absent_score=-1., num_classes=4, reduction='none', ignore_index=None)\n",
    "        iou_all = iou_all[iou_all != -1.]\n",
    "        if len(iou_all) == 0:\n",
    "            val_iou = torch.tensor(0.0).cuda()\n",
    "        else:\n",
    "            val_iou = iou_all.mean()\n",
    "        # dice score\n",
    "        dice_all = dice_score(soft_out, mask, bg=True, no_fg_score=-1., reduction='none')\n",
    "        dice_all = dice_all[dice_all != -1.]\n",
    "        if len(dice_all) == 0:\n",
    "            val_dice = torch.tensor(0.0).cuda()\n",
    "        else:\n",
    "            val_dice = dice_all.mean()\n",
    "        # logger\n",
    "        self.log('val_loss', loss, on_step=True, on_epoch=False, prog_bar=True)\n",
    "        return {'loss': loss, 'val_iou': val_iou, 'val_dice': val_dice}\n",
    "\n",
    "    def training_epoch_end(self, train_step_outputs):\n",
    "        \"\"\"-----Calculate and logs the average train loss, IoU score and Dice Score-----\"\"\"\n",
    "        avg_train_loss = torch.stack([x['loss'] for x in train_step_outputs]).mean()\n",
    "        avg_train_iou = torch.stack([x['train_iou'] for x in train_step_outputs]).mean()\n",
    "        avg_train_dice = torch.stack([x['train_dice'] for x in train_step_outputs]).mean()\n",
    "        self.log('avg_train_loss', avg_train_loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log('avg_train_iou', avg_train_iou, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log('avg_train_dice', avg_train_dice, on_step=False, on_epoch=True, prog_bar=True)\n",
    "\n",
    "    def validation_epoch_end(self, val_step_outputs):\n",
    "        \"\"\"-----Calculate and logs the average validation loss, IoU score and Dice Score-----\"\"\"\n",
    "        avg_val_loss = torch.stack([x['loss'] for x in val_step_outputs]).mean()\n",
    "        avg_val_iou = torch.stack([x['val_iou'] for x in val_step_outputs]).mean()\n",
    "        avg_val_dice = torch.stack([x['val_dice'] for x in val_step_outputs]).mean()\n",
    "        self.log('avg_val_loss', avg_val_loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log('avg_val_iou', avg_val_iou, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log('avg_val_dice', avg_val_dice, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        return {'avg_val_loss': avg_val_loss, 'avg_val_iou': avg_val_iou, 'avg_val_dice': avg_val_dice}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"-----Optimizers and LR Schedulers-----\"\"\"\n",
    "        if optimizer_choice == 'adam':\n",
    "            optim = torch.optim.Adam(self.net.parameters(), lr=learning_rate, eps=1e-8, weight_decay=1e-5, amsgrad=True)\n",
    "        else:\n",
    "            raise ValueError(\"Wrong optimizer!\")\n",
    "        if scheduler_choice == 'plateau':\n",
    "            scheduler = ReduceLROnPlateau(optim, mode='min', factor=LR_decay_rate, patience=scheduler_patience)\n",
    "        elif scheduler_choice == 'step':\n",
    "            scheduler = StepLR(optim, step_size=20, gamma=LR_decay_rate)\n",
    "        else:\n",
    "            raise ValueError(\"Wrong scheduler!\")\n",
    "        return {\n",
    "            \"optimizer\": optim,\n",
    "            \"lr_scheduler\": scheduler,\n",
    "            'monitor': 'avg_train_loss'\n",
    "        }\n",
    "\n",
    "\n",
    "#   Reset the parameters of the model for the next fold\n",
    "def reset_weights(m):\n",
    "    if isinstance(m, nn.Conv3d) or isinstance(m, nn.Conv2d) or \\\n",
    "            isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.ConvTranspose3d):\n",
    "        m.reset_parameters()\n",
    "\n",
    "\n",
    "def run_training():\n",
    "    \"\"\" 5 fold Cross Validation\"\"\"\n",
    "    for fold, (train_idx, val_idx) in enumerate(splits.split(np.arange(len(concatenated_dataset)))):\n",
    "        print(\"--------------------------\", \"Fold\", fold + 1, \"--------------------------\")\n",
    "        print(\"Train Batch Size:\", batch_size_train,\n",
    "              \"Val Batch Size:\", batch_size_val,\n",
    "              \"Learning Rate:\", lr,\n",
    "              \"Max epochs:\", maximum_epochs)\n",
    "\n",
    "        \"\"\"-------------------Train the model for \"max_epochs\" for each fold-------------------\"\"\"\n",
    "        # training dataset\n",
    "        training_data = DataLoader(train_loader_ACDC(transform=train_compose, train_index=train_idx),\n",
    "                                   batch_size=batch_size_train,\n",
    "                                   shuffle=True)\n",
    "        # validation dataset\n",
    "        validation_data = DataLoader(val_loader_ACDC(val_index=val_idx, transform=val_compose),\n",
    "                                     batch_size=batch_size_val,\n",
    "                                     shuffle=False)\n",
    "        # init the model\n",
    "        model = Train_3D()\n",
    "        # name of the model\n",
    "        name = str(model_choice) + \"_\" + str(dropout_rate) + \"_\" + str(datetime.date.today()) + \"_Fold_\" + str(fold + 1)\n",
    "        #  Checkpoint callback and Early Stopping\n",
    "        checkpoint_callback = pl.callbacks.ModelCheckpoint(dirpath=checkpoint_path,\n",
    "                                                           save_top_k=1,\n",
    "                                                           save_last=True,\n",
    "                                                           verbose=True,\n",
    "                                                           monitor='avg_val_iou',\n",
    "                                                           mode='max',\n",
    "                                                           filename=name + \"_\" + '{epoch}-{avg_val_iou:.3f}',\n",
    "                                                           )\n",
    "        early_stop_callback = pl.callbacks.EarlyStopping(monitor='avg_val_loss',\n",
    "                                                         min_delta=0.00,\n",
    "                                                         patience=patience_early_stop,\n",
    "                                                         verbose=False,\n",
    "                                                         mode='min')\n",
    "        # tensorboard --logdir .\n",
    "        tensorboard_logger = TensorBoardLogger(tb_path, name=name)\n",
    "        # CSV logger\n",
    "        csv_logger = CSVLogger(csv_path, name=name)\n",
    "        # Trainer for training\n",
    "        trainer = Trainer(max_epochs=maximum_epochs, callbacks=[early_stop_callback, checkpoint_callback],\n",
    "                          gpus=1, logger=[tensorboard_logger, csv_logger],\n",
    "                          fast_dev_run=False, log_every_n_steps=2)\n",
    "        # Training the model\n",
    "        trainer.fit(model, train_dataloader=training_data, val_dataloaders=validation_data)\n",
    "        # Save the best model\n",
    "        file_name = str(model_choice) + \"_Best_\" + str(dropout_rate) + \"_Fold_\" + str(fold + 1)\n",
    "        best_model_path = checkpoint_callback.best_model_path\n",
    "        model = model.load_from_checkpoint(best_model_path)\n",
    "        model.eval().cuda()\n",
    "        if not os.path.exists(r'unet/best_models/'):\n",
    "            os.makedirs(r'unet/best_models/')\n",
    "        torch.save(model, str(Path('unet/best_models/', file_name + '.pt')))\n",
    "\n",
    "        # Folders to save the validation images for each fold\n",
    "        if not os.path.exists(os.path.join(r'unet/', name, f\"{fold + 1}_Fold\")):\n",
    "            os.makedirs(os.path.join(r'unet/', name, f\"{fold + 1}_Fold\"))\n",
    "        val_images_path = os.path.join(r'unet/', name, f\"{fold + 1}_Fold\")\n",
    "\n",
    "        #  Move the validated images to the respective folders\n",
    "        for filename in glob.glob(os.path.join(val_path, '*.*')):\n",
    "            shutil.move(filename, val_images_path)\n",
    "\n",
    "        # Save plots --> Loss, IoU and Dice\n",
    "        plot_out_path = str(Path(r\"unet/Plots/\", name))\n",
    "        if not os.path.exists(plot_out_path):\n",
    "            os.makedirs(plot_out_path)\n",
    "\n",
    "        event_acc = ea(str(Path(r\"unet/tb_logs/\", name, \"version_0\")))\n",
    "        event_acc.Reload()\n",
    "\n",
    "        _, _, training_loss = zip(*event_acc.Scalars('avg_train_loss'))\n",
    "        _, _, validation_loss = zip(*event_acc.Scalars('avg_val_loss'))\n",
    "        _, _, training_iou = zip(*event_acc.Scalars('avg_train_iou'))\n",
    "        _, _, validation_iou = zip(*event_acc.Scalars('avg_val_iou'))\n",
    "        _, _, training_dice = zip(*event_acc.Scalars('avg_train_dice'))\n",
    "        _, _, validation_dice = zip(*event_acc.Scalars('avg_val_dice'))\n",
    "\n",
    "        t_loss, v_loss, t_iou, v_iou, t_dice, v_dice = np.array(training_loss), np.array(validation_loss), \\\n",
    "                                                       np.array(training_iou), np.array(validation_iou), \\\n",
    "                                                       np.array(training_dice), np.array(validation_dice)\n",
    "        min_length = min(len(t_loss), len(v_loss), len(t_iou), len(v_iou), len(t_dice), len(v_dice))\n",
    "        total_epochs = np.arange(1, min_length + 1)\n",
    "\n",
    "        # Save the Loss, IoU and Dice plots\n",
    "        plt.figure(1)\n",
    "        plt.rcParams.update({'font.size': 15})\n",
    "        plt.plot(total_epochs, t_loss[0:min_length], 'X-', label='Training Loss', linewidth=2.0)\n",
    "        plt.plot(total_epochs, v_loss[0:min_length], 'o-', label='Validation Loss', linewidth=2.0)\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.minorticks_on()\n",
    "        plt.grid(which='minor', linestyle='--')\n",
    "        plt.savefig(str(Path(plot_out_path, 'Loss_Plot.png')), bbox_inches='tight', format='png', dpi=300)\n",
    "        plt.close()  # Always plt.close() to save memory\n",
    "\n",
    "        plt.figure(2)\n",
    "        plt.rcParams.update({'font.size': 15})\n",
    "        plt.plot(total_epochs, t_iou[0:min_length], 'X-', label='Training IOU', linewidth=2.0)\n",
    "        plt.plot(total_epochs, v_iou[0:min_length], 'o-', label='Validation IOU', linewidth=2.0)\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('IOU')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.minorticks_on()\n",
    "        plt.grid(which='minor', linestyle='--')\n",
    "        plt.savefig(str(Path(plot_out_path, 'Iou_Plot.png')), bbox_inches='tight', format='png', dpi=300)\n",
    "        plt.close()  # Always plt.close() to save memory\n",
    "\n",
    "        plt.figure(3)\n",
    "        plt.rcParams.update({'font.size': 15})\n",
    "        plt.plot(total_epochs, t_dice[0:min_length], 'X-', label='Training Dice', linewidth=2.0)\n",
    "        plt.plot(total_epochs, v_dice[0:min_length], 'o-', label='Validation Dice', linewidth=2.0)\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Dice Score')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.minorticks_on()\n",
    "        plt.grid(which='minor', linestyle='--')\n",
    "        plt.savefig(str(Path(plot_out_path, 'Dice_Plot.png')), bbox_inches='tight', format='png', dpi=300)\n",
    "        plt.close()  # Always plt.close() to save memory\n",
    "\n",
    "        # reset parameters for the next fold\n",
    "        model.apply(reset_weights)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_training()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TugasAkhir",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
